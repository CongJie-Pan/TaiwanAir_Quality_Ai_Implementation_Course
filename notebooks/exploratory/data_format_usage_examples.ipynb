{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Air Quality Data Format Usage Examples\n",
    "\n",
    "This notebook demonstrates how to use the converted air quality data formats:\n",
    "- Parquet files (fast, compressed, columnar storage)\n",
    "- DuckDB database (SQL query support)\n",
    "- Data loader utilities (convenient Python interface)\n",
    "\n",
    "**Author:** Claude Code  \n",
    "**Date:** 2025-10-13"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "\n",
    "# Add project root to Python path\n",
    "project_root = Path.cwd().parent.parent\n",
    "sys.path.insert(0, str(project_root / 'src' / 'main' / 'python'))\n",
    "\n",
    "# Import our custom utilities\n",
    "from utils.data_loader import AirQualityDataLoader, load_air_quality_data, query_air_quality\n",
    "\n",
    "# Configure plotting\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette('husl')\n",
    "%matplotlib inline\n",
    "\n",
    "print(\"✓ Imports successful\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Basic Data Loading from Parquet\n",
    "\n",
    "Parquet files provide fast, compressed storage with efficient column-wise access."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize data loader\n",
    "loader = AirQualityDataLoader()\n",
    "\n",
    "# Get basic information about the dataset\n",
    "min_date, max_date = loader.get_date_range()\n",
    "print(f\"Data available from {min_date} to {max_date}\")\n",
    "\n",
    "# Get list of monitoring stations\n",
    "stations = loader.get_station_list()\n",
    "print(f\"\\nTotal monitoring stations: {len(stations)}\")\n",
    "print(f\"\\nSample stations:\")\n",
    "print(stations[['sitename', 'county']].head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Loading Data with Filters\n",
    "\n",
    "Efficiently load only the data you need using filters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load one month of data for Taipei City\n",
    "df_taipei = loader.load_parquet(\n",
    "    start_date='2024-08-01',\n",
    "    end_date='2024-08-31',\n",
    "    counties=['Taipei City']\n",
    ")\n",
    "\n",
    "print(f\"Loaded {len(df_taipei):,} rows\")\n",
    "print(f\"\\nDataset info:\")\n",
    "print(df_taipei.info())\n",
    "print(f\"\\nSample data:\")\n",
    "df_taipei.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data for specific stations\n",
    "df_stations = loader.load_parquet(\n",
    "    start_date='2024-08-01',\n",
    "    end_date='2024-08-31',\n",
    "    stations=['Zhongshan', 'Wanhua', 'Songshan'],\n",
    "    columns=['date', 'sitename', 'aqi', 'pm2.5', 'pm10', 'o3']\n",
    ")\n",
    "\n",
    "print(f\"Loaded {len(df_stations):,} rows for selected stations\")\n",
    "df_stations.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Loading Data by Year\n",
    "\n",
    "Data is partitioned by year for efficient access."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all data for 2024\n",
    "df_2024 = loader.load_by_year(2024)\n",
    "\n",
    "print(f\"2024 data: {len(df_2024):,} rows\")\n",
    "print(f\"Date range: {df_2024['date'].min()} to {df_2024['date'].max()}\")\n",
    "print(f\"\\nCounties covered:\")\n",
    "print(df_2024['county'].value_counts().head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. SQL Queries with DuckDB\n",
    "\n",
    "Use SQL for complex analytical queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query: Average AQI by county for 2024\n",
    "df_county_avg = loader.query_db(\"\"\"\n",
    "    SELECT \n",
    "        county,\n",
    "        COUNT(*) as measurement_count,\n",
    "        AVG(aqi) as avg_aqi,\n",
    "        MAX(aqi) as max_aqi,\n",
    "        AVG(pm2_5) as avg_pm25\n",
    "    FROM air_quality\n",
    "    WHERE year = 2024\n",
    "    GROUP BY county\n",
    "    ORDER BY avg_aqi DESC\n",
    "\"\"\")\n",
    "\n",
    "print(\"Average AQI by County (2024):\")\n",
    "df_county_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query: Top 10 stations with highest average PM2.5\n",
    "df_top_pm25 = loader.query_db(\"\"\"\n",
    "    SELECT \n",
    "        sitename,\n",
    "        county,\n",
    "        AVG(pm2_5) as avg_pm25,\n",
    "        MAX(pm2_5) as max_pm25,\n",
    "        COUNT(*) as measurements\n",
    "    FROM air_quality\n",
    "    WHERE year = 2024 AND pm2_5 IS NOT NULL\n",
    "    GROUP BY sitename, county\n",
    "    ORDER BY avg_pm25 DESC\n",
    "    LIMIT 10\n",
    "\"\"\")\n",
    "\n",
    "print(\"Top 10 Stations by Average PM2.5 (2024):\")\n",
    "df_top_pm25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query: Monthly trends using the pre-built view\n",
    "df_monthly = loader.query_db(\"\"\"\n",
    "    SELECT \n",
    "        year,\n",
    "        month,\n",
    "        county,\n",
    "        avg_aqi,\n",
    "        avg_pm25\n",
    "    FROM monthly_summary\n",
    "    WHERE year = 2024 AND county = 'Taipei City'\n",
    "    ORDER BY month\n",
    "\"\"\")\n",
    "\n",
    "print(\"Monthly Trends for Taipei City (2024):\")\n",
    "df_monthly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Summary Statistics\n",
    "\n",
    "Get quick summary statistics using convenience functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get summary statistics for all counties\n",
    "summary_all = loader.get_summary_stats()\n",
    "print(\"Summary Statistics by County:\")\n",
    "summary_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get summary for a specific county\n",
    "summary_taipei = loader.get_summary_stats(county='Taipei City')\n",
    "print(\"Summary Statistics for Taipei City:\")\n",
    "summary_taipei"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Time Series Analysis\n",
    "\n",
    "Analyze temporal patterns in air quality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load recent data for time series analysis\n",
    "df_recent = load_air_quality_data(\n",
    "    start_date='2024-08-01',\n",
    "    end_date='2024-08-31',\n",
    "    county='Taipei City'\n",
    ")\n",
    "\n",
    "# Calculate daily averages\n",
    "df_daily = df_recent.groupby(df_recent['date'].dt.date).agg({\n",
    "    'aqi': 'mean',\n",
    "    'pm2.5': 'mean',\n",
    "    'pm10': 'mean',\n",
    "    'o3': 'mean'\n",
    "}).reset_index()\n",
    "\n",
    "# Plot time series\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "axes[0, 0].plot(df_daily['date'], df_daily['aqi'])\n",
    "axes[0, 0].set_title('Daily Average AQI')\n",
    "axes[0, 0].set_xlabel('Date')\n",
    "axes[0, 0].set_ylabel('AQI')\n",
    "axes[0, 0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "axes[0, 1].plot(df_daily['date'], df_daily['pm2.5'], color='orange')\n",
    "axes[0, 1].set_title('Daily Average PM2.5')\n",
    "axes[0, 1].set_xlabel('Date')\n",
    "axes[0, 1].set_ylabel('PM2.5 (μg/m³)')\n",
    "axes[0, 1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "axes[1, 0].plot(df_daily['date'], df_daily['pm10'], color='red')\n",
    "axes[1, 0].set_title('Daily Average PM10')\n",
    "axes[1, 0].set_xlabel('Date')\n",
    "axes[1, 0].set_ylabel('PM10 (μg/m³)')\n",
    "axes[1, 0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "axes[1, 1].plot(df_daily['date'], df_daily['o3'], color='green')\n",
    "axes[1, 1].set_title('Daily Average O3')\n",
    "axes[1, 1].set_xlabel('Date')\n",
    "axes[1, 1].set_ylabel('O3 (ppb)')\n",
    "axes[1, 1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"✓ Time series plots generated\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Spatial Analysis\n",
    "\n",
    "Analyze air quality patterns across different locations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get average AQI by station with geographic coordinates\n",
    "df_spatial = loader.query_db(\"\"\"\n",
    "    SELECT \n",
    "        sitename,\n",
    "        county,\n",
    "        AVG(longitude) as longitude,\n",
    "        AVG(latitude) as latitude,\n",
    "        AVG(aqi) as avg_aqi,\n",
    "        AVG(pm2_5) as avg_pm25\n",
    "    FROM air_quality\n",
    "    WHERE year = 2024 AND longitude IS NOT NULL\n",
    "    GROUP BY sitename, county\n",
    "\"\"\")\n",
    "\n",
    "# Create scatter plot colored by AQI\n",
    "plt.figure(figsize=(12, 10))\n",
    "scatter = plt.scatter(\n",
    "    df_spatial['longitude'],\n",
    "    df_spatial['latitude'],\n",
    "    c=df_spatial['avg_aqi'],\n",
    "    s=100,\n",
    "    cmap='RdYlGn_r',\n",
    "    alpha=0.6,\n",
    "    edgecolors='black'\n",
    ")\n",
    "plt.colorbar(scatter, label='Average AQI')\n",
    "plt.xlabel('Longitude')\n",
    "plt.ylabel('Latitude')\n",
    "plt.title('Average AQI by Monitoring Station (2024)')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "print(\"✓ Spatial distribution plot generated\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Pollution Event Analysis\n",
    "\n",
    "Identify and analyze high pollution events."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query high pollution events using the pre-built view\n",
    "df_high_pollution = loader.query_db(\"\"\"\n",
    "    SELECT *\n",
    "    FROM high_pollution_events\n",
    "    WHERE year = 2024\n",
    "    LIMIT 20\n",
    "\"\"\")\n",
    "\n",
    "print(\"Top 20 High Pollution Events (AQI > 100) in 2024:\")\n",
    "df_high_pollution[['date', 'sitename', 'county', 'aqi', 'pollutant', 'status']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze pollution status distribution\n",
    "df_status = loader.query_db(\"\"\"\n",
    "    SELECT \n",
    "        status,\n",
    "        COUNT(*) as count,\n",
    "        AVG(aqi) as avg_aqi\n",
    "    FROM air_quality\n",
    "    WHERE year = 2024 AND status IS NOT NULL\n",
    "    GROUP BY status\n",
    "    ORDER BY avg_aqi\n",
    "\"\"\")\n",
    "\n",
    "# Create bar chart\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(df_status['status'], df_status['count'])\n",
    "plt.xlabel('Air Quality Status')\n",
    "plt.ylabel('Number of Measurements')\n",
    "plt.title('Distribution of Air Quality Status (2024)')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nAir Quality Status Distribution:\")\n",
    "print(df_status)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Performance Comparison\n",
    "\n",
    "Compare query performance between different data formats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# Benchmark: Load one month of data from Parquet\n",
    "start = time.time()\n",
    "df_parquet = loader.load_parquet(\n",
    "    start_date='2024-08-01',\n",
    "    end_date='2024-08-31'\n",
    ")\n",
    "parquet_time = time.time() - start\n",
    "\n",
    "# Benchmark: Same query using DuckDB SQL\n",
    "start = time.time()\n",
    "df_duckdb = loader.query_db(\"\"\"\n",
    "    SELECT *\n",
    "    FROM air_quality\n",
    "    WHERE date BETWEEN '2024-08-01' AND '2024-08-31'\n",
    "\"\"\")\n",
    "duckdb_time = time.time() - start\n",
    "\n",
    "print(\"Performance Comparison:\")\n",
    "print(f\"Parquet load time: {parquet_time:.2f} seconds ({len(df_parquet):,} rows)\")\n",
    "print(f\"DuckDB query time: {duckdb_time:.2f} seconds ({len(df_duckdb):,} rows)\")\n",
    "print(f\"\\nSpeedup factor: {max(parquet_time, duckdb_time) / min(parquet_time, duckdb_time):.2f}x\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Cleanup\n",
    "\n",
    "Close database connections when done."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close database connection\n",
    "loader.close()\n",
    "print(\"✓ Database connection closed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook demonstrated:\n",
    "\n",
    "1. **Loading data from Parquet files** with filters\n",
    "2. **SQL queries with DuckDB** for complex analytics\n",
    "3. **Convenience functions** for common operations\n",
    "4. **Time series analysis** of air quality trends\n",
    "5. **Spatial analysis** of pollution patterns\n",
    "6. **Event detection** for high pollution episodes\n",
    "7. **Performance comparisons** between formats\n",
    "\n",
    "### Key Takeaways\n",
    "\n",
    "- **Parquet format** provides fast, efficient storage (70-80% smaller than CSV)\n",
    "- **DuckDB** enables powerful SQL analytics without loading full dataset\n",
    "- **Data loader utilities** provide convenient Python interface\n",
    "- **Partitioning by year** enables efficient data access\n",
    "- **Pre-built views** simplify common query patterns\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "- Explore more advanced time series analysis (seasonality, trends)\n",
    "- Build machine learning models for air quality prediction\n",
    "- Create interactive dashboards with Plotly/Dash\n",
    "- Integrate with external data sources (weather, traffic)\n",
    "- Develop real-time monitoring and alerting systems"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
