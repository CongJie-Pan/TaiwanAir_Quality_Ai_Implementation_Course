"""
Application Utility Functions for Air Quality Streamlit App

This module provides core utility functions for the Streamlit application including:
- Session state initialization and management
- Data preparation and SPCT dimension label generation
- Air quality structure calculations (similar to sales structure)
- Common aggregation and filtering functions
- Operation logging

Author: Claude Code
Date: 2025-10-14
"""

import streamlit as st
import pandas as pd
import numpy as np
from datetime import datetime
from typing import Optional, List, Dict, Any
import logging

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


def init_session_state(project_name: str = "ç©ºæ°£è³ªé‡åˆ†æç³»çµ±") -> Any:
    """
    Initialize all session state variables for the Streamlit application.

    This function sets up persistent variables that maintain state across
    page navigations and user interactions.

    Args:
        project_name: Name of the project for logging purposes

    Returns:
        Streamlit session_state object with initialized variables

    Example:
        >>> sss = init_session_state("Air Quality Analysis")
        >>> sss.df is None
        True
    """
    sss = st.session_state

    # Data storage
    if 'df' not in sss:
        sss.df = None
    if 'df_filtered' not in sss:
        sss.df_filtered = None

    # User selections - data filters
    if 'selected_counties' not in sss:
        sss.selected_counties = []
    if 'selected_stations' not in sss:
        sss.selected_stations = []
    if 'selected_pollutants' not in sss:
        sss.selected_pollutants = ['PM2.5', 'PM10']
    if 'date_range' not in sss:
        sss.date_range = None

    # Analysis parameters
    if 'stat_method' not in sss:
        sss.stat_method = "å¹³å‡å€¼"
    if 'time_agg' not in sss:
        sss.time_agg = "æ—¥"
    if 'aqi_threshold' not in sss:
        sss.aqi_threshold = 100

    # Analysis results cache
    if 'analysis_result' not in sss:
        sss.analysis_result = None
    if 'crosstab_result' not in sss:
        sss.crosstab_result = None

    # Operation log
    if 'log' not in sss:
        sss.log = [f"[{datetime.now().strftime('%H:%M:%S')}] {project_name} åˆå§‹åŒ–"]

    # Note: user input fields removed per requirements (no user feature)

    return sss


def add_log(message: str, log_list: Optional[List[str]] = None) -> None:
    """
    Add timestamped entry to operation log.

    Args:
        message: Log message to add
        log_list: Optional log list (defaults to session_state.log)

    Example:
        >>> add_log("è¼‰å…¥æ•¸æ“šå®Œæˆ")
        >>> st.session_state.log[-1]
        '[14:30:45] è¼‰å…¥æ•¸æ“šå®Œæˆ'
    """
    if log_list is None:
        log_list = st.session_state.log

    timestamp = datetime.now().strftime("%H:%M:%S")
    log_entry = f"[{timestamp}] {message}"
    log_list.append(log_entry)
    logger.info(message)


def prepare_data(df: pd.DataFrame) -> pd.DataFrame:
    """
    Prepare data by generating SPCT dimension labels and derived attributes.

    This function implements the data transformation described in PLANNING.md
    for the SPCT model (Space, Pollutant, Condition, Time dimensions).

    Args:
        df: Raw air quality DataFrame

    Returns:
        DataFrame with additional dimension labels

    Dimension Labels Generated:
        - Time (T): year, month, day, hour, dayofweek, quarter, season, yq, ym
        - Space (S): region (derived from county)
        - Pollutant (P): pollutant_category, aqi_level
        - Condition (C): wind_level, time_period, is_weekend
    """
    df = df.copy()

    # ===== Time Dimension (T) =====
    # Convert date to datetime if needed
    if not pd.api.types.is_datetime64_any_dtype(df['date']):
        df['date'] = pd.to_datetime(df['date'])

    # Extract time components
    df['year'] = df['date'].dt.year
    df['month'] = df['date'].dt.month
    df['day'] = df['date'].dt.day
    df['hour'] = df['date'].dt.hour
    df['dayofweek'] = df['date'].dt.dayofweek

    # Quarter labels
    df['quarter'] = pd.cut(df['month'],
                           bins=[0, 3, 6, 9, 12],
                           labels=['Q1', 'Q2', 'Q3', 'Q4'])

    # Season labels (Chinese)
    df['season'] = pd.cut(df['month'],
                          bins=[0, 3, 6, 9, 12],
                          labels=['å†¬å­£', 'æ˜¥å­£', 'å¤å­£', 'ç§‹å­£'])

    # Year-quarter combination (e.g., "24Q3")
    df['yq'] = df['year'].astype(str).str[-2:] + df['quarter'].astype(str)

    # Year-month combination
    df['ym'] = df['date'].dt.to_period('M').astype(str)

    # Weekend indicator
    df['is_weekend'] = df['dayofweek'] >= 5

    # Time period of day
    # Use unique labels to avoid pandas Categorical error when ordered=True
    df['time_period'] = pd.cut(
        df['hour'],
        bins=[-1, 6, 9, 12, 18, 21, 24],
        labels=['å‡Œæ™¨', 'æ—©æ™¨', 'ä¸Šåˆ', 'ä¸‹åˆ', 'å‚æ™š', 'å¤œé–“']
    )

    # ===== Space Dimension (S) =====
    # Region classification (support both Chinese and English county names)
    region_map = {
        # Chinese names
        'å°åŒ—å¸‚': 'åŒ—éƒ¨', 'æ–°åŒ—å¸‚': 'åŒ—éƒ¨', 'åŸºéš†å¸‚': 'åŒ—éƒ¨',
        'æ¡ƒåœ’å¸‚': 'åŒ—éƒ¨', 'æ–°ç«¹å¸‚': 'åŒ—éƒ¨', 'æ–°ç«¹ç¸£': 'åŒ—éƒ¨',
        'å°ä¸­å¸‚': 'ä¸­éƒ¨', 'å½°åŒ–ç¸£': 'ä¸­éƒ¨', 'å—æŠ•ç¸£': 'ä¸­éƒ¨',
        'è‹—æ —ç¸£': 'ä¸­éƒ¨', 'é›²æ—ç¸£': 'ä¸­éƒ¨',
        'é«˜é›„å¸‚': 'å—éƒ¨', 'å°å—å¸‚': 'å—éƒ¨', 'å±æ±ç¸£': 'å—éƒ¨',
        'å˜‰ç¾©å¸‚': 'å—éƒ¨', 'å˜‰ç¾©ç¸£': 'å—éƒ¨',
        'èŠ±è“®ç¸£': 'æ±éƒ¨', 'å°æ±ç¸£': 'æ±éƒ¨',
        'æ¾æ¹–ç¸£': 'é›¢å³¶', 'é‡‘é–€ç¸£': 'é›¢å³¶', 'é€£æ±Ÿç¸£': 'é›¢å³¶',

        # English names
        'Taipei City': 'åŒ—éƒ¨', 'New Taipei City': 'åŒ—éƒ¨', 'Keelung City': 'åŒ—éƒ¨',
        'Taoyuan City': 'åŒ—éƒ¨', 'Hsinchu City': 'åŒ—éƒ¨', 'Hsinchu County': 'åŒ—éƒ¨',
        'Taichung City': 'ä¸­éƒ¨', 'Changhua County': 'ä¸­éƒ¨', 'Nantou County': 'ä¸­éƒ¨',
        'Miaoli County': 'ä¸­éƒ¨', 'Yunlin County': 'ä¸­éƒ¨',
        'Kaohsiung City': 'å—éƒ¨', 'Tainan City': 'å—éƒ¨', 'Pingtung County': 'å—éƒ¨',
        'Chiayi City': 'å—éƒ¨', 'Chiayi County': 'å—éƒ¨',
        'Hualien County': 'æ±éƒ¨', 'Taitung County': 'æ±éƒ¨',
        'Penghu County': 'é›¢å³¶', 'Kinmen County': 'é›¢å³¶', 'Lienchiang County': 'é›¢å³¶'
    }
    df['region'] = df['county'].map(region_map)

    # Log if any counties are not mapped
    unmapped_counties = df[df['region'].isna()]['county'].unique()
    if len(unmapped_counties) > 0:
        logger.warning(f"Unmapped counties found: {unmapped_counties}")

    # ===== Pollutant Dimension (P) =====
    # AQI level classification
    def classify_aqi(aqi):
        if pd.isna(aqi):
            return None
        elif aqi <= 50:
            return 'è‰¯å¥½'
        elif aqi <= 100:
            return 'æ™®é€š'
        elif aqi <= 150:
            return 'å°æ•æ„Ÿæ—ç¾¤ä¸å¥åº·'
        elif aqi <= 200:
            return 'ä¸å¥åº·'
        elif aqi <= 300:
            return 'éå¸¸ä¸å¥åº·'
        else:
            return 'å±å®³'

    df['aqi_level'] = df['aqi'].apply(classify_aqi)

    # Pollutant category
    pollutant_category_map = {
        'PM2.5': 'æ‡¸æµ®å¾®ç²’',
        'PM10': 'æ‡¸æµ®å¾®ç²’',
        'O3': 'æ°£æ…‹æ±¡æŸ“ç‰©',
        'CO': 'æ°£æ…‹æ±¡æŸ“ç‰©',
        'SO2': 'æ°£æ…‹æ±¡æŸ“ç‰©',
        'NO2': 'æ°£æ…‹æ±¡æŸ“ç‰©',
        'NOx': 'æ°£æ…‹æ±¡æŸ“ç‰©'
    }
    df['pollutant_category'] = df['pollutant'].map(pollutant_category_map)

    # ===== Condition Dimension (C) =====
    # Wind speed level
    df['wind_level'] = pd.cut(df['windspeed'],
                              bins=[0, 1, 3, 5, float('inf')],
                              labels=['ç„¡é¢¨', 'å¾®é¢¨', 'è¼•é¢¨', 'å¼·é¢¨'],
                              include_lowest=True)

    # Pollution status indicator
    df['is_exceed'] = df['aqi'] > 100

    logger.info(f"Data prepared: {len(df)} rows with SPCT dimension labels")

    return df


def ç©ºæ°£è³ªé‡çµæ§‹(df: pd.DataFrame, group_by: str = 'county') -> pd.DataFrame:
    """
    Calculate air quality structure metrics (analogous to sales structure).

    This function computes aggregated metrics similar to the æˆäº¤çµæ§‹ function
    in the course reference code, adapted for air quality data.

    Args:
        df: Air quality DataFrame
        group_by: Column name to group by (e.g., 'county', 'yq', 'season')

    Returns:
        DataFrame with air quality structure metrics

    Metrics Calculated:
        - ç›£æ¸¬ç«™æ•¸ (number of stations)
        - æ¸¬é‡æ¬¡æ•¸ (number of measurements)
        - å¹³å‡AQI, AQIä¸­ä½æ•¸, æœ€é«˜AQI, æœ€ä½AQI
        - å¹³å‡PM2.5, å¹³å‡PM10, å¹³å‡O3
        - é”æ¨™ç‡ (compliance rate: AQI <= 100)

    Example:
        >>> structure = ç©ºæ°£è³ªé‡çµæ§‹(df, 'county')
        >>> structure[['county', 'å¹³å‡AQI', 'é”æ¨™ç‡']]
    """
    result = df.groupby(group_by).agg({
        'sitename': 'nunique',
        'date': 'count',
        'aqi': ['mean', 'median', 'max', 'min'],
        'pm2.5': 'mean',
        'pm10': 'mean',
        'o3': 'mean'
    }).reset_index()

    # Flatten multi-level columns
    result.columns = [
        group_by,
        'ç›£æ¸¬ç«™æ•¸', 'æ¸¬é‡æ¬¡æ•¸',
        'å¹³å‡AQI', 'AQIä¸­ä½æ•¸', 'æœ€é«˜AQI', 'æœ€ä½AQI',
        'å¹³å‡PM2.5', 'å¹³å‡PM10', 'å¹³å‡O3'
    ]

    # Calculate derived metrics
    # Compliance rate: percentage of measurements with AQI <= 100
    compliance = df[df['aqi'] <= 100].groupby(group_by).size()
    total = df.groupby(group_by).size()
    result['é”æ¨™ç‡'] = (compliance / total * 100).fillna(0).round(1)

    # Average measurements per station
    result['ç«™å‡æ¸¬é‡æ¬¡æ•¸'] = (result['æ¸¬é‡æ¬¡æ•¸'] / result['ç›£æ¸¬ç«™æ•¸']).round(0)

    # Round numeric columns
    result['å¹³å‡AQI'] = result['å¹³å‡AQI'].round(1)
    result['AQIä¸­ä½æ•¸'] = result['AQIä¸­ä½æ•¸'].round(1)
    result['å¹³å‡PM2.5'] = result['å¹³å‡PM2.5'].round(1)
    result['å¹³å‡PM10'] = result['å¹³å‡PM10'].round(1)
    result['å¹³å‡O3'] = result['å¹³å‡O3'].round(1)

    logger.info(f"Air quality structure calculated for {len(result)} groups")

    return result


def get_aqi_color(aqi: float) -> str:
    """
    Get color code for AQI level visualization.

    Args:
        aqi: AQI value

    Returns:
        Hex color code
    """
    if pd.isna(aqi):
        return "#CCCCCC"
    elif aqi <= 50:
        return "#00E400"  # Green - Good
    elif aqi <= 100:
        return "#FFFF00"  # Yellow - Moderate
    elif aqi <= 150:
        return "#FF7E00"  # Orange - Unhealthy for sensitive groups
    elif aqi <= 200:
        return "#FF0000"  # Red - Unhealthy
    elif aqi <= 300:
        return "#8F3F97"  # Purple - Very unhealthy
    else:
        return "#7E0023"  # Maroon - Hazardous


def get_aqi_recommendation(aqi: float, user_group: str = "ä¸€èˆ¬æ°‘çœ¾") -> str:
    """
    Generate health recommendation based on AQI level and user group.

    Args:
        aqi: Current AQI value
        user_group: User group category

    Returns:
        Health recommendation text in Traditional Chinese
    """
    advice_matrix = {
        'ä¸€èˆ¬æ°‘çœ¾': {
            (0, 50): "âœ… ç©ºæ°£å“è³ªè‰¯å¥½ï¼Œé©åˆå„ç¨®æˆ¶å¤–æ´»å‹•ã€‚",
            (51, 100): "âœ… ç©ºæ°£å“è³ªæ™®é€šï¼Œå¯æ­£å¸¸æˆ¶å¤–æ´»å‹•ã€‚",
            (101, 150): "âš ï¸ å»ºè­°æ¸›å°‘é•·æ™‚é–“åŠ‡çƒˆé‹å‹•ã€‚",
            (151, 200): "ğŸš« æ‡‰æ¸›å°‘æˆ¶å¤–æ´»å‹•ï¼Œå¤–å‡ºæ™‚é…æˆ´å£ç½©ã€‚",
            (201, 500): "â›” é¿å…æˆ¶å¤–æ´»å‹•ï¼Œé—œé–‰é–€çª—ï¼Œä½¿ç”¨ç©ºæ°£æ¸…æ·¨æ©Ÿã€‚"
        },
        'æ•æ„Ÿæ—ç¾¤': {
            (0, 50): "âœ… ç©ºæ°£å“è³ªè‰¯å¥½ï¼Œå¯æ­£å¸¸æ´»å‹•ã€‚",
            (51, 100): "âš ï¸ ç©ºæ°£å“è³ªæ™®é€šï¼Œæ³¨æ„èº«é«”ç‹€æ³ï¼Œæ¸›å°‘åŠ‡çƒˆæ´»å‹•ã€‚",
            (101, 150): "ğŸš« æ‡‰æ¸›å°‘æˆ¶å¤–æ´»å‹•ï¼Œå¿…è¦å¤–å‡ºæ™‚é…æˆ´å£ç½©ã€‚",
            (151, 500): "â›” é¿å…æ‰€æœ‰æˆ¶å¤–æ´»å‹•ï¼Œç•™åœ¨å®¤å…§ä¸¦ä½¿ç”¨ç©ºæ°£æ¸…æ·¨æ©Ÿã€‚"
        },
        'æˆ¶å¤–å·¥ä½œè€…': {
            (0, 50): "âœ… ç©ºæ°£å“è³ªè‰¯å¥½ï¼Œå¯æ­£å¸¸å·¥ä½œã€‚",
            (51, 100): "âœ… ç©ºæ°£å“è³ªæ™®é€šï¼Œå¯æ­£å¸¸å·¥ä½œï¼Œå¤šè£œå……æ°´åˆ†ã€‚",
            (101, 150): "âš ï¸ å»ºè­°ç¸®çŸ­æˆ¶å¤–å·¥ä½œæ™‚é–“ï¼Œé…æˆ´å£ç½©ï¼Œå¤šä¼‘æ¯ã€‚",
            (151, 500): "ğŸš« æ‡‰æš«åœæˆ¶å¤–å·¥ä½œæˆ–æ¡å–é˜²è­·æªæ–½ï¼Œé »ç¹ä¼‘æ¯ã€‚"
        },
        'é‹å‹•æ„›å¥½è€…': {
            (0, 50): "âœ… ç©ºæ°£å“è³ªè‰¯å¥½ï¼Œé©åˆå„ç¨®é‹å‹•ã€‚",
            (51, 100): "âœ… ç©ºæ°£å“è³ªæ™®é€šï¼Œå¯æ­£å¸¸é‹å‹•ã€‚",
            (101, 150): "âš ï¸ æ¸›å°‘é«˜å¼·åº¦é‹å‹•ï¼Œæ”¹ç‚ºå®¤å…§é‹å‹•ã€‚",
            (151, 500): "ğŸš« é¿å…æˆ¶å¤–é‹å‹•ï¼Œå»ºè­°æ”¹ç‚ºå®¤å…§é‹å‹•æˆ–ä¼‘æ¯ã€‚"
        }
    }

    if pd.isna(aqi):
        return "æ•¸æ“šç•°å¸¸ï¼Œè«‹æŸ¥çœ‹æœ€æ–°å®˜æ–¹å…¬å‘Šã€‚"

    for (min_aqi, max_aqi), advice in advice_matrix.get(user_group, advice_matrix['ä¸€èˆ¬æ°‘çœ¾']).items():
        if min_aqi <= aqi <= max_aqi:
            return advice

    return "æ•¸æ“šç•°å¸¸ï¼Œè«‹æŸ¥çœ‹æœ€æ–°å®˜æ–¹å…¬å‘Šã€‚"


def filter_data(
    df: pd.DataFrame,
    start_date: Optional[str] = None,
    end_date: Optional[str] = None,
    counties: Optional[List[str]] = None,
    stations: Optional[List[str]] = None,
    pollutants: Optional[List[str]] = None
) -> pd.DataFrame:
    """
    Filter DataFrame based on multiple criteria.

    Args:
        df: Input DataFrame
        start_date: Start date string (YYYY-MM-DD)
        end_date: End date string (YYYY-MM-DD)
        counties: List of counties to include
        stations: List of stations to include
        pollutants: List of pollutants to filter by

    Returns:
        Filtered DataFrame
    """
    filtered_df = df.copy()

    if start_date:
        filtered_df = filtered_df[filtered_df['date'] >= pd.to_datetime(start_date)]

    if end_date:
        filtered_df = filtered_df[filtered_df['date'] <= pd.to_datetime(end_date)]

    if counties and len(counties) > 0:
        filtered_df = filtered_df[filtered_df['county'].isin(counties)]

    if stations and len(stations) > 0:
        filtered_df = filtered_df[filtered_df['sitename'].isin(stations)]

    if pollutants and len(pollutants) > 0:
        # This filter is for primary pollutant
        filtered_df = filtered_df[filtered_df['pollutant'].isin(pollutants)]

    logger.info(f"Filtered data: {len(filtered_df)} rows")

    return filtered_df
