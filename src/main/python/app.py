"""
Taiwan Air Quality Data Analysis System - Main Application

This is the main Streamlit application implementing the DIKW hierarchy
(Data â†’ Information â†’ Knowledge â†’ Wisdom) for air quality analysis.

Based on:
- PLANNING.md: System architecture and SPCT model
- AIp04ç©ºé–“èˆ‡ç¶²ç«™X.py: Navigation and session state patterns

Features:
- 5 pages corresponding to DIKW layers
- Interactive sidebar controls for data filtering
- Session state management for data persistence
- Operation logging system

Usage:
    streamlit run src/main/python/app.py

Author: Claude Code
Date: 2025-10-14
"""

import streamlit as st
from streamlit_navigation_bar import st_navbar
import sys
from pathlib import Path
import os
import logging

# Add current directory to Python path for imports
current_dir = Path(__file__).parent
if str(current_dir) not in sys.path:
    sys.path.insert(0, str(current_dir))

from utils.app_utils import init_session_state, add_log, prepare_data, filter_data
from utils.data_loader import AirQualityDataLoader
import pandas as pd
from datetime import datetime, timedelta


# ==================== Page Configuration ====================

st.set_page_config(
    page_title="å°ç£ç©ºæ°£è³ªé‡åˆ†æç³»çµ±",
    page_icon="ğŸŒ",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Ensure the main view container remains scrollable in case any component
# injects restrictive CSS (observed in some nav bar themes)
st.markdown(
    """
    <style>
    html, body, #root, .stApp {
        height: 100% !important;
        overflow-y: auto !important;
    }
    [data-testid="stAppViewContainer"] {
        overflow-y: auto !important;
        overflow-x: hidden;
    }
    main.block-container, section.main {
        overflow: visible !important;
    }
    [data-testid="stHeader"], header {
        position: sticky; top: 0; z-index: 10;
    }
    </style>
    """,
    unsafe_allow_html=True
)


# ==================== Navigation Bar ====================

pages = [
    "[æ•¸æ“šç¸½è¦½]",      # Data Layer
    "[çµ±è¨ˆåˆ†æ]",      # Information Layer
    "[è¦å¾‹ç™¼ç¾]",      # Knowledge Layer
    "[æ™ºæ…§æ±ºç­–]",      # Wisdom Layer
    "[é æ¸¬æ¨¡å‹]"       # Wisdom Layer Advanced
]

use_top_nav = os.getenv("USE_TOP_NAV", "0").lower() in ("1", "true", "yes", "y")
if use_top_nav:
    page = st_navbar(pages)
    nav_mode = "navbar"
else:
    page = st.sidebar.radio("é é¢å°èˆª", pages, index=0)
    nav_mode = "sidebar"

# Re-apply scroll CSS after navbar renders to ensure our overrides win
st.markdown(
    """
    <style>
    /* post-navbar scroll fix */
    html, body, #root, .stApp { height: 100% !important; overflow-y: auto !important; }
    [data-testid=\"stAppViewContainer\"] { overflow-y: auto !important; overflow-x: hidden; }
    main.block-container, section.main { overflow: visible !important; }
    [data-testid=\"stHeader\"], header { position: sticky; top: 0; z-index: 10; }
    </style>
    """,
    unsafe_allow_html=True
)

# Debug UI toggle and logger
DEBUG_UI = os.getenv("DEBUG_UI", "0").lower() in ("1", "true", "yes", "y")
CSS_PATCH_VERSION = "scrollfix-2025-10-14#post"
logger = logging.getLogger(__name__)
if not logger.handlers:
    logging.basicConfig(level=logging.INFO)
if DEBUG_UI:
    st.sidebar.markdown("---")
    st.sidebar.markdown("### ğŸ› Debug Info")
    st.sidebar.text(f"Nav mode: {nav_mode}")
    st.sidebar.text(f"CSS patch: {CSS_PATCH_VERSION}")
    st.sidebar.text(f"Page: {page}")
    logger.info(f"[DEBUG] Nav mode={nav_mode}, CSS={CSS_PATCH_VERSION}, Page={page}")

## Remove duplicate/legacy debug block (migrated above)


# ==================== Session State Initialization ====================

sss = init_session_state("å°ç£ç©ºæ°£è³ªé‡åˆ†æç³»çµ±")


# ==================== Main Title ====================

st.title("ğŸŒ å°ç£ç©ºæ°£è³ªé‡åˆ†æç³»çµ±")
st.markdown("### åŸºæ–¼DIKWåŸå‰‡çš„å¤šç¶­åº¦ç©ºæ°£è³ªé‡åˆ†æå¹³å°")
st.markdown("---")


# ==================== Sidebar Control Panel ====================

st.sidebar.title("ğŸ“Š ç©ºæ°£è³ªé‡åˆ†ææ§åˆ¶ç›¤")
st.sidebar.markdown("---")


# ===== Data Loading Section =====
st.sidebar.header("ğŸ”§ ã€æ•¸æ“šè¼‰å…¥ã€‘")

@st.cache_resource
def get_data_loader():
    """Get singleton data loader instance"""
    return AirQualityDataLoader()


@st.cache_data
def load_initial_data():
    """Load initial data for date range and county options"""
    try:
        loader = get_data_loader()
        min_date, max_date = loader.get_date_range()
        # Derive stations directly from the fact table to keep naming consistent
        station_source = "air_quality"
        try:
            stations = loader.query_db(
                "SELECT DISTINCT sitename, county FROM air_quality ORDER BY sitename"
            )
        except Exception:
            stations = loader.get_station_list()
            station_source = "station_metadata/fallback"
        return min_date, max_date, stations
    except Exception as e:
        st.sidebar.error(f"ç„¡æ³•è¼‰å…¥æ•¸æ“šå…ƒä¿¡æ¯: {e}")
        return None, None, None


# Load metadata
min_date, max_date, stations_df = load_initial_data()

if min_date is None:
    st.error("âš ï¸ ç„¡æ³•é€£æ¥åˆ°æ•¸æ“šæºã€‚è«‹ç¢ºèªæ•¸æ“šæ–‡ä»¶å­˜åœ¨ã€‚")
    st.info("""
    è«‹ç¢ºèªä»¥ä¸‹æ–‡ä»¶å­˜åœ¨ï¼š
    - `data/processed/air_quality.duckdb` æˆ–
    - `data/processed/*.parquet`
    """)
    st.stop()

st.sidebar.success(f"âœ… æ•¸æ“šå¯ç”¨æœŸé–“: {min_date.date()} ~ {max_date.date()}")
if DEBUG_UI:
    try:
        # Show station source if available in closure (best-effort; harmless if not)
        st.sidebar.caption("[DEBUG] Station list source: air_quality (distinct)")
    except Exception:
        pass


# ===== Data Filtering Section =====
st.sidebar.header("ğŸ” ã€æ•¸æ“šç¯©é¸ã€‘")

# Date range selection
default_end_date = max_date.date()
default_start_date = (max_date - timedelta(days=30)).date()

date_range = st.sidebar.date_input(
    "é¸æ“‡æ™‚é–“ç¯„åœ",
    value=(default_start_date, default_end_date),
    min_value=min_date.date(),
    max_value=max_date.date(),
    help="é¸æ“‡è¦åˆ†æçš„æ—¥æœŸå€é–“"
)

# Handle date range selection
if isinstance(date_range, tuple) and len(date_range) == 2:
    start_date, end_date = date_range
else:
    start_date = date_range
    end_date = date_range
# Persist active date range for pages
st.session_state['date_range'] = (start_date, end_date)

# County selection
if stations_df is not None:
    available_counties = sorted(stations_df['county'].unique())

    # Create safe default list - only use counties that actually exist
    preferred_defaults = ['å°åŒ—å¸‚', 'æ–°åŒ—å¸‚', 'å°ä¸­å¸‚', 'é«˜é›„å¸‚']
    safe_defaults = [c for c in preferred_defaults if c in available_counties]

    # If no preferred counties found, use first 4 available counties
    if not safe_defaults and len(available_counties) >= 4:
        safe_defaults = list(available_counties[:4])
    elif not safe_defaults and len(available_counties) > 0:
        safe_defaults = [available_counties[0]]
    else:
        safe_defaults = []

    selected_counties = st.sidebar.multiselect(
        "é¸æ“‡ç¸£å¸‚",
        options=available_counties,
        default=safe_defaults,
        help="é¸æ“‡è¦åˆ†æçš„ç¸£å¸‚ï¼ˆå¯å¤šé¸ï¼‰"
    )
    # Persist counties selection for pages
    st.session_state['selected_counties'] = selected_counties

    # Station selection (filtered by selected counties AND date range for accuracy)
    try:
        loader_for_station = get_data_loader()
        base_where = f"date BETWEEN '{default_start_date}' AND '{default_end_date}'"
        # Use current sidebar date selection for availability
        base_where = f"date BETWEEN '{start_date}' AND '{end_date}'"
        if selected_counties:
            counties_str = "', '".join([c.replace("'", "''") for c in selected_counties])
            sql_st = f"""
                SELECT DISTINCT sitename
                FROM air_quality
                WHERE {base_where} AND county IN ('{counties_str}')
                ORDER BY sitename
            """
        else:
            sql_st = f"""
                SELECT DISTINCT sitename
                FROM air_quality
                WHERE {base_where}
                ORDER BY sitename
            """
        st_df = loader_for_station.query_db(sql_st)
        available_stations = st_df['sitename'].tolist()
    except Exception:
        # Fallback to preloaded station list if DB query fails
        if selected_counties:
            available_stations = sorted(
                stations_df[stations_df['county'].isin(selected_counties)]['sitename'].unique()
            )
        else:
            available_stations = sorted(stations_df['sitename'].unique())

    # Preserve prior selection but drop any stations not available in current window
    prev_selected = list(st.session_state.get('selected_stations', []))
    default_selected = [s for s in prev_selected if s in available_stations]
    if prev_selected and len(default_selected) < len(prev_selected):
        st.sidebar.warning("éƒ¨åˆ†å…ˆå‰é¸æ“‡çš„ç«™é»åœ¨ç›®å‰æ™‚é–“/ç¸£å¸‚æ¢ä»¶ä¸‹ç„¡è³‡æ–™ï¼Œå·²è‡ªå‹•ç§»é™¤ã€‚")
    selected_stations = st.sidebar.multiselect(
        "é¸æ“‡ç›£æ¸¬ç«™",
        options=available_stations,
        default=default_selected,
        key='selected_stations',
        help="ä¾ç›®å‰é¸æ“‡çš„ç¸£å¸‚èˆ‡æ™‚é–“ç¯„åœé¡¯ç¤ºå¯ç”¨ç«™é»ã€‚ç•™ç©ºï¼å…¨éƒ¨"
    )

    # Compute whether loading makes sense (avoid empty result when counties selected butç„¡ç«™é»)
    can_load = True
    if selected_counties and len(available_stations) == 0:
        can_load = False
        st.sidebar.error("ç•¶å‰æ™‚é–“ç¯„åœå…§ï¼Œæ‰€é¸ç¸£å¸‚æ²’æœ‰ä»»ä½•æœ‰æ•ˆç›£æ¸¬ç«™ã€‚è«‹èª¿æ•´æ¢ä»¶ã€‚")
else:
    selected_counties = []
    selected_stations = []

# Pollutant selection
pollutant_options = ['PM2.5', 'PM10', 'O3', 'CO', 'SO2', 'NO2']
selected_pollutants = st.sidebar.multiselect(
    "ä¸»è¦æ±¡æŸ“ç‰©ç¯©é¸",
    options=pollutant_options,
    default=['PM2.5', 'PM10'],
    help="é¸æ“‡è¦é—œæ³¨çš„æ±¡æŸ“ç‰©é¡å‹"
)


# ===== Analysis Parameters Section =====
st.sidebar.markdown("---")
st.sidebar.header("âš™ï¸ ã€åˆ†æåƒæ•¸ã€‘")

stat_method = st.sidebar.selectbox(
    "çµ±è¨ˆæ–¹æ³•",
    ["å¹³å‡å€¼", "ä¸­ä½æ•¸", "æœ€å¤§å€¼", "æœ€å°å€¼"],
    help="é¸æ“‡æ•¸æ“šèšåˆæ–¹å¼"
)

time_agg = st.sidebar.radio(
    "æ™‚é–“èšåˆå±¤ç´š",
    ["å°æ™‚", "æ—¥", "é€±", "æœˆ", "å­£", "å¹´"],
    index=1,
    help="é¸æ“‡æ™‚é–“ç¶­åº¦çš„èšåˆå–®ä½"
)

aqi_threshold = st.sidebar.slider(
    "AQIè­¦ç¤ºé–¾å€¼",
    min_value=0,
    max_value=200,
    value=100,
    step=10,
    help="è¨­å®šç©ºæ°£å“è³ªè­¦ç¤ºçš„AQIé–¾å€¼"
)


# ===== Load Data Button =====
st.sidebar.markdown("---")

if st.sidebar.button("ğŸ”„ è¼‰å…¥/æ›´æ–°æ•¸æ“š", type="primary", disabled=not can_load):
    with st.spinner("è¼‰å…¥æ•¸æ“šä¸­..."):
        try:
            loader = get_data_loader()

            # Build SQL query for efficient loading
            def _escape(values):
                return [v.replace("'", "''") for v in values]

            base_where = f"date BETWEEN '{start_date}' AND '{end_date}'"

            if selected_stations:
                # Prefer station filter to avoid county label mismatches excluding stations
                stations_esc = "', '".join(_escape(selected_stations))
                sql = f"""
                    SELECT *
                    FROM air_quality
                    WHERE {base_where}
                      AND sitename IN ('{stations_esc}')
                """
            elif selected_counties:
                counties_esc = "', '".join(_escape(selected_counties))
                sql = f"""
                    SELECT *
                    FROM air_quality
                    WHERE {base_where}
                      AND county IN ('{counties_esc}')
                """
            else:
                sql = f"""
                    SELECT *
                    FROM air_quality
                    WHERE {base_where}
                """

            if DEBUG_UI:
                st.sidebar.markdown("#### [DEBUG] SQL")
                st.sidebar.code(sql.strip())

            # Load data
            df = loader.query_db(sql)

            # Save available stations before filtering for error messages
            available_stations_in_data = df['sitename'].unique()

            # Debug: Show actual data format
            st.sidebar.info(f"""
            ğŸ” Debug è³‡è¨Šï¼š
            - SQLæŸ¥è©¢å¾Œè¨˜éŒ„æ•¸: {len(df):,}
            - å”¯ä¸€ç¸£å¸‚: {df['county'].nunique()} å€‹
            - ç¸£å¸‚ç¯„ä¾‹: {', '.join(df['county'].unique()[:3])}
            - å”¯ä¸€ç«™é»: {df['sitename'].nunique()} å€‹
            - ç«™é»ç¯„ä¾‹: {', '.join(available_stations_in_data[:3])}
            """)

            # Apply station filter if specified
            if selected_stations:
                st.sidebar.markdown("### ğŸ” ç«™é»åŒ¹é…è©³ç´°è¨ºæ–·")

                # Show user selections with detailed format
                st.sidebar.write("**ç”¨æˆ¶é¸æ“‡çš„ç«™é»ï¼š**")
                for i, station in enumerate(selected_stations, 1):
                    st.sidebar.text(f"{i}. '{station}' (é•·åº¦: {len(station)})")

                # Show available stations in data with detailed format
                st.sidebar.write("**è³‡æ–™åº«ä¸­ç¬¦åˆæ¢ä»¶çš„ç«™é»ï¼š**")
                for i, station in enumerate(available_stations_in_data[:10], 1):
                    st.sidebar.text(f"{i}. '{station}' (é•·åº¦: {len(station)})")

                # Perform matching and show results
                st.sidebar.write("**åŒ¹é…çµæœï¼š**")
                matched = []
                unmatched = []
                for station in selected_stations:
                    if station in available_stations_in_data:
                        matched.append(station)
                        st.sidebar.success(f"âœ… '{station}' - åŒ¹é…æˆåŠŸ")
                    else:
                        unmatched.append(station)
                        st.sidebar.error(f"âŒ '{station}' - æœªæ‰¾åˆ°")
                        # Try to find similar names
                        similar = [s for s in available_stations_in_data if station.lower() in s.lower() or s.lower() in station.lower()]
                        if similar:
                            st.sidebar.info(f"   ğŸ’¡ ç›¸ä¼¼åç¨±: {similar[:3]}")

                # Sanity-check in database: exact-match existence per station (all time and current range)
                st.sidebar.write("**è³‡æ–™åº«ç²¾ç¢ºæª¢æŸ¥ï¼š**")
                for station in selected_stations:
                    s_esc = station.replace("'", "''")
                    try:
                        exists_df = loader.query_db(
                            f"SELECT COUNT(*) AS cnt FROM air_quality WHERE sitename = '{s_esc}'"
                        )
                        cnt = int(exists_df['cnt'].iloc[0]) if not exists_df.empty else 0
                        range_df = loader.query_db(
                            f"SELECT COUNT(*) AS cnt FROM air_quality WHERE sitename = '{s_esc}' AND date BETWEEN '{start_date}' AND '{end_date}'"
                        )
                        cnt_range = int(range_df['cnt'].iloc[0]) if not range_df.empty else 0
                    except Exception:
                        cnt = -1
                        cnt_range = -1
                    st.sidebar.text(f"- '{station}': å…¨æœŸé–“ {cnt} ç­† | ç›®å‰å€é–“ {cnt_range} ç­†")

                # Prefix LIKE check (before parenthesis) to show similar entries in fact table
                st.sidebar.write("**è³‡æ–™åº«è¿‘ä¼¼æª¢æŸ¥ï¼ˆå‰ç¶´ LIKEï¼‰ï¼š**")
                for station in selected_stations:
                    prefix = station.split(' (')[0].strip()
                    p_esc = prefix.replace("'", "''")
                    try:
                        like_df = loader.query_db(
                            f"""
                            SELECT DISTINCT sitename
                            FROM air_quality
                            WHERE sitename ILIKE '{p_esc}%'
                            ORDER BY sitename
                            """
                        )
                        examples = like_df['sitename'].tolist()[:5]
                    except Exception:
                        examples = []
                    st.sidebar.text(f"- å‰ç¶´ '{prefix}': {examples}")

                # Apply filter
                df_before = len(df)
                stations_before = df['sitename'].nunique()
                df = df[df['sitename'].isin(selected_stations)]
                stations_after = df['sitename'].nunique()

                st.sidebar.info(f"ğŸ”§ ç«™é»éæ¿¾: {df_before:,} â†’ {len(df):,} ç­†è¨˜éŒ„")
                st.sidebar.info(f"ğŸ”§ éæ¿¾å¾Œå”¯ä¸€ç«™é»æ•¸: {stations_after} / {len(selected_stations)}")

                # Validation: Check if filtering worked
                if len(df) == 0:
                    st.sidebar.error("âŒ ç«™é»éæ¿¾å¾Œç„¡æ•¸æ“šï¼æ‰€æœ‰é¸æ“‡çš„ç«™é»éƒ½æœªåŒ¹é…ã€‚")
                    st.stop()  # Stop execution if no data
                elif stations_after < len(selected_stations):
                    st.sidebar.warning(f"âš ï¸ åªæœ‰ {stations_after}/{len(selected_stations)} å€‹ç«™é»æˆåŠŸè¼‰å…¥")
                    st.sidebar.info(f"æˆåŠŸè¼‰å…¥: {list(df['sitename'].unique())}")
                    st.sidebar.info(f"æœªèƒ½è¼‰å…¥: {unmatched}")

            # Prepare data with SPCT dimension labels
            df = prepare_data(df)

            # Debug: Show region mapping result
            if 'region' in df.columns:
                nan_count = df['region'].isna().sum()
                if nan_count > 0:
                    st.sidebar.warning(f"âš ï¸ å€åŸŸæ˜ å°„å¤±æ•—: {nan_count} ç­†è¨˜éŒ„çš„å€åŸŸç‚º NaN")
                    st.sidebar.info(f"æœªæ˜ å°„çš„ç¸£å¸‚: {df[df['region'].isna()]['county'].unique()}")

            # Store in session state
            sss.df = df
            sss.df_filtered = df

            # Log the operation
            add_log(f"è¼‰å…¥æ•¸æ“š: {len(df):,} ç­†è¨˜éŒ„ ({start_date} ~ {end_date})")

            st.sidebar.success(f"âœ… æˆåŠŸè¼‰å…¥ {len(df):,} ç­†è¨˜éŒ„ï¼Œ{df['sitename'].nunique()} å€‹ç«™é»")

        except Exception as e:
            st.sidebar.error(f"âŒ è¼‰å…¥æ•¸æ“šå¤±æ•—: {e}")
            add_log(f"æ•¸æ“šè¼‰å…¥å¤±æ•—: {e}")


# ===== Current Status Section =====
st.sidebar.markdown("---")
st.sidebar.header("ğŸ“ˆ ã€ç•¶å‰ç‹€æ…‹ã€‘")

if sss.df is not None:
    st.sidebar.metric("æ•¸æ“šç­†æ•¸", f"{len(sss.df):,}")
    st.sidebar.metric("ç›£æ¸¬ç«™æ•¸", f"{sss.df['sitename'].nunique()}")
    st.sidebar.metric("æ™‚é–“ç¯„åœ", f"{(sss.df['date'].max() - sss.df['date'].min()).days} å¤©")

    if len(sss.df) > 0:
        avg_aqi = sss.df['aqi'].mean()
        st.sidebar.metric("å¹³å‡AQI", f"{avg_aqi:.1f}")
else:
    st.sidebar.info("å°šæœªè¼‰å…¥æ•¸æ“š")


# User input section removed per requirement (no user feature)


# ===== Operation Log Section =====
st.sidebar.markdown("---")
st.sidebar.markdown("### ğŸ“‹ æ“ä½œLOGæ—¥èªŒ")

# Display last 10 log entries
for i, log_entry in enumerate(sss.log[-10:], 1):
    st.sidebar.text(f"{len(sss.log) - 10 + i}. {log_entry}")


# ==================== Page Routing ====================

# Check if data is loaded
if sss.df is None:
    st.warning("âš ï¸ è«‹å…ˆåœ¨å´é‚Šæ¬„è¼‰å…¥æ•¸æ“šä»¥é–‹å§‹åˆ†æ")
    st.info("""
    ### ä½¿ç”¨èªªæ˜ï¼ˆå´é‚Šæ¬„æ§åˆ¶ç›¤ï¼‰

    æ§åˆ¶ç›¤å€å¡Šèªªæ˜ï¼š
    - ã€æ•¸æ“šè¼‰å…¥ã€‘é¡¯ç¤ºå¯ç”¨æ—¥æœŸç¯„åœï¼›è‹¥è³‡æ–™ä¸å­˜åœ¨æœƒæç¤ºæª¢æŸ¥è·¯å¾‘
    - ã€æ•¸æ“šç¯©é¸ã€‘ä¾åºé¸æ“‡ï¼š
      - æ™‚é–“ç¯„åœï¼šé–‹å§‹èˆ‡çµæŸæ—¥æœŸï¼ˆå¿…é¸ï¼‰
      - ç¸£å¸‚ï¼šå¯å¤šé¸ï¼›ç•™ç©ºè¡¨ç¤ºå…¨éƒ¨
      - ç›£æ¸¬ç«™ï¼šæœƒä¾é¸æ“‡çš„ç¸£å¸‚ç¯©å‡ºç«™é»ï¼›ç•™ç©ºè¡¨ç¤ºå…¨éƒ¨
      - ä¸»è¦æ±¡æŸ“ç‰©ï¼šåƒ…ç¯©é¸ä¸»æ±¡æŸ“ç‰©æ¬„ä½
    - ã€åˆ†æåƒæ•¸ã€‘
      - çµ±è¨ˆæ–¹æ³•ï¼šå¹³å‡å€¼/ä¸­ä½æ•¸/æœ€å¤§å€¼/æœ€å°å€¼
      - æ™‚é–“èšåˆå±¤ç´šï¼šå°æ™‚/æ—¥/é€±/æœˆ/å­£/å¹´ï¼ˆéƒ¨åˆ†åœ–è¡¨ä½¿ç”¨ï¼‰
      - AQI è­¦ç¤ºé–¾å€¼ï¼šç”¨æ–¼è¶¨å‹¢ç·šèˆ‡æé†’
    - ã€ŒğŸ”„ è¼‰å…¥/æ›´æ–°æ•¸æ“šã€ï¼šä¾ä¸Šè¿°æ¢ä»¶è¼‰å…¥è³‡æ–™ä¸¦å¥—ç”¨
    - ã€ç•¶å‰ç‹€æ…‹ã€‘ï¼šé¡¯ç¤ºç­†æ•¸ã€ç«™æ•¸ã€è³‡æ–™æ™‚é–“ç¯„åœèˆ‡å¹³å‡ AQI
    - ã€æ“ä½œLOGæ—¥èªŒã€‘ï¼šé¡¯ç¤ºæœ€è¿‘æ“ä½œèˆ‡æç¤º

    ä½¿ç”¨æ­¥é©Ÿï¼š
    1. åœ¨ã€æ•¸æ“šç¯©é¸ã€‘é¸å¥½æ™‚é–“ã€ç¸£å¸‚ï¼ˆå¯é¸ï¼‰ã€ç«™é»ï¼ˆå¯é¸ï¼‰
    2. è¦–éœ€è¦èª¿æ•´ã€åˆ†æåƒæ•¸ã€‘
    3. æŒ‰ã€ŒğŸ”„ è¼‰å…¥/æ›´æ–°æ•¸æ“šã€é€²è¡Œè¼‰å…¥
    4. é€éä¸Šæ–¹å°èˆªåˆ—åˆ‡æ›å„åˆ†æé é¢

    å°æé†’ï¼š
    - ç¸£å¸‚/ç«™é»ç•™ç©º = ä¸é™åˆ¶ï¼ˆå…¨é¸ï¼‰
    - é‡æ–°èª¿æ•´æ¢ä»¶å¾Œï¼Œéœ€å†æ¬¡æŒ‰ä¸‹ã€Œè¼‰å…¥/æ›´æ–°æ•¸æ“šã€æ‰æœƒç”Ÿæ•ˆ

    ### DIKW åˆ†æå±¤ç´š
    - **æ•¸æ“šç¸½è¦½**ï¼šæŸ¥çœ‹åŸå§‹æ•¸æ“šèˆ‡åŸºæœ¬æŒ‡æ¨™
    - **çµ±è¨ˆåˆ†æ**ï¼šæ¯”è¼ƒåˆ†å¸ƒã€çµ±è¨ˆé‡èˆ‡è¶¨å‹¢
    - **è¦å¾‹ç™¼ç¾**ï¼šæ¢ç´¢ç›¸é—œæ€§ã€ç†±åŠ›åœ–ã€é¢¨ç«ç‘°åœ–ç­‰
    - **æ™ºæ…§æ±ºç­–**ï¼šå–å¾—å¥åº·å»ºè­°èˆ‡ç­–ç•¥åƒè€ƒ
    - **é æ¸¬æ¨¡å‹**ï¼šå±•ç¤ºé æ¸¬çµæœï¼ˆé é¢æ¶æ§‹å·²å‚™å¦¥ï¼‰
    """)
    st.stop()


# Import and render appropriate page
try:
    match page:
        case "[æ•¸æ“šç¸½è¦½]":
            from pages import page1_data_overview
            if DEBUG_UI:
                st.sidebar.text("[DEBUG] Rendering: æ•¸æ“šç¸½è¦½ (start)")
                logger.info("[DEBUG] Rendering page: æ•¸æ“šç¸½è¦½ (start)")
            page1_data_overview.render(sss.df)
            add_log("ç€è¦½ï¼šæ•¸æ“šç¸½è¦½é é¢")
            if DEBUG_UI:
                st.sidebar.text("[DEBUG] Rendering: æ•¸æ“šç¸½è¦½ (done)")
                logger.info("[DEBUG] Rendering page: æ•¸æ“šç¸½è¦½ (done)")

        case "[çµ±è¨ˆåˆ†æ]":
            from pages import page2_statistical_analysis
            if DEBUG_UI:
                st.sidebar.text("[DEBUG] Rendering: çµ±è¨ˆåˆ†æ (start)")
                logger.info("[DEBUG] Rendering page: çµ±è¨ˆåˆ†æ (start)")
            page2_statistical_analysis.render(sss.df)
            add_log("ç€è¦½ï¼šçµ±è¨ˆåˆ†æé é¢")
            if DEBUG_UI:
                st.sidebar.text("[DEBUG] Rendering: çµ±è¨ˆåˆ†æ (done)")
                logger.info("[DEBUG] Rendering page: çµ±è¨ˆåˆ†æ (done)")

        case "[è¦å¾‹ç™¼ç¾]":
            from pages import page3_pattern_discovery
            if DEBUG_UI:
                st.sidebar.text("[DEBUG] Rendering: è¦å¾‹ç™¼ç¾ (start)")
                logger.info("[DEBUG] Rendering page: è¦å¾‹ç™¼ç¾ (start)")
            page3_pattern_discovery.render(sss.df)
            add_log("ç€è¦½ï¼šè¦å¾‹ç™¼ç¾é é¢")
            if DEBUG_UI:
                st.sidebar.text("[DEBUG] Rendering: è¦å¾‹ç™¼ç¾ (done)")
                logger.info("[DEBUG] Rendering page: è¦å¾‹ç™¼ç¾ (done)")

        case "[æ™ºæ…§æ±ºç­–]":
            from pages import page4_wisdom_decision
            if DEBUG_UI:
                st.sidebar.text("[DEBUG] Rendering: æ™ºæ…§æ±ºç­– (start)")
                logger.info("[DEBUG] Rendering page: æ™ºæ…§æ±ºç­– (start)")
            page4_wisdom_decision.render(sss.df)
            add_log("ç€è¦½ï¼šæ™ºæ…§æ±ºç­–é é¢")
            if DEBUG_UI:
                st.sidebar.text("[DEBUG] Rendering: æ™ºæ…§æ±ºç­– (done)")
                logger.info("[DEBUG] Rendering page: æ™ºæ…§æ±ºç­– (done)")

        case "[é æ¸¬æ¨¡å‹]":
            from pages import page5_prediction_model
            if DEBUG_UI:
                st.sidebar.text("[DEBUG] Rendering: é æ¸¬æ¨¡å‹ (start)")
                logger.info("[DEBUG] Rendering page: é æ¸¬æ¨¡å‹ (start)")
            page5_prediction_model.render(sss.df)
            add_log("ç€è¦½ï¼šé æ¸¬æ¨¡å‹é é¢")
            if DEBUG_UI:
                st.sidebar.text("[DEBUG] Rendering: é æ¸¬æ¨¡å‹ (done)")
                logger.info("[DEBUG] Rendering page: é æ¸¬æ¨¡å‹ (done)")

except Exception as e:
    st.error(f"âŒ é é¢è¼‰å…¥éŒ¯èª¤: {e}")
    st.exception(e)


# ==================== Footer ====================

st.markdown("---")
st.markdown("""
<div style='text-align: center; color: gray;'>
    <p>å°ç£ç©ºæ°£è³ªé‡åˆ†æç³»çµ± | åŸºæ–¼DIKWåŸå‰‡èˆ‡SPCTå¤šç¶­åº¦æ¨¡å‹</p>
    <p>æ•¸æ“šä¾†æº: å°ç£ç’°ä¿ç½²ç©ºæ°£è³ªé‡ç›£æ¸¬ç¶² | é–‹ç™¼: Claude Code</p>
</div>
""", unsafe_allow_html=True)
